# Treat NA -----------------------------------------------------------#
housing.dropna(subset=["total_bedrooms"]) # Remove row with NA
housing.drop("total_bedrooms", axis=1) # Remove entire Column

housing["total_bedrooms"].fillna(median) # fill-in with median

# OR sklearn fill-in with median
from sklearn.preprocessing import Imputer
imputer = Imputer(strategy="median")
housing_num = housing.drop("ocean_proximity", axis=1) # Remove Categorical columns
imputer.fit(housing_num) # fill-in with median for all columns

imputer.statistics_ # contains medians for each column. Save this so you can apply to test dataset too
housing_num.median().values # same value as above

X = imputer.transform(housing_num) # Replace NA with medians
housing_tr = pd.DataFrame(X, columns=housing_num.columns) # convert numpy array to Pandas Dataframe


# Cateogory to Numeric  -----------------------------------------------------------#
# Option 1: Text to number
from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
housing_cat = housing["ocean_proximity"]
housing_cat_encoded = encoder.fit_transform(housing_cat)
housing_cat_encoded
print(encoder.classes_) # Mapping

# Option 2: One-Hot-Encoder. Continues from Option 1
from sklearn.preprocessing import OneHotEncoder
encoder = OneHotEncoder()
housing_cat_1hot = encoder.fit_transform(housing_cat_encoded.reshape(-1,1))
housing_cat_1hot.toarray()

# Combine Option 1 and 2:
from sklearn.preprocessing import LabelBinarizer
housing_cat = housing["ocean_proximity"]
encoder = LabelBinarizer()
housing_cat_1hot = encoder.fit_transform(housing_cat)
housing_cat_1hot


# Pipeline to Combine transfomrs ----------------------------------------------#
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

from sklearn.pipeline import FeatureUnion
num_attribs = list(housing_num)
cat_attribs = ["ocean_proximity"]
num_pipeline = Pipeline([
    ('selector', DataFrameSelector(num_attribs)),
    ('imputer', Imputer(strategy="median")),
    ('attribs_adder', CombinedAttributesAdder()),
    ('std_scaler', StandardScaler()),
  ])
cat_pipeline = Pipeline([
    ('selector', DataFrameSelector(cat_attribs)),
    ('label_binarizer', LabelBinarizer()),
  ])
full_pipeline = FeatureUnion(transformer_list=[
    ("num_pipeline", num_pipeline),
    ("cat_pipeline", cat_pipeline),
  ])

housing_prepared = full_pipeline.fit_transform(housing)


# Split Train and Test Dataset -----------------------------------#

np.random.seed(42)

import numpy as np
def split_train_test(data, test_ratio):
  shuffled_indices = np.random.permutation(len(data))
  test_set_size = int(len(data) * test_ratio)
  test_indices = shuffled_indices[:test_set_size]
  train_indices = shuffled_indices[test_set_size:]
  return data.iloc[train_indices], data.iloc[test_indices]
  
train_set, test_set = split_train_test(housing, 0.2)


# time based split -----------------------------------#

np.random.seed(42)

# Sort Data
df1 = df1.sort_values('TREND').reset_index().drop('index',axis=1)
df1.head()

# Find row where to split test dataset
val_obs = df1[df1.TREND == 22].index.min()
val_obs

x_train1 = np.array(df1[['ADJ_EMPID']].iloc[0:val_obs])
x_train2 = np.array(df1.iloc[0:val_obs, 2:])
y_train = np.array(df1[['SRC']].iloc[0:val_obs])

x_test1 = np.array(df1[['ADJ_EMPID']].iloc[val_obs:])
x_test2 = np.array(df1.iloc[val_obs:, 2:])
y_test = np.array(df1[['SRC']].iloc[val_obs:])


# Stratified Sampling -----------------------------------#

from sklearn.model_selection import StratifiedShuffleSplit

split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
for train_index, test_index in split.split(housing, housing["income_cat"]):
  strat_train_set = housing.loc[train_index]
  strat_test_set = housing.loc[test_index]
  
housing["income_cat"].value_counts() / len(housing)
